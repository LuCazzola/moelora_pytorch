# MoeLoRA PyTorch

A lightweight PyTorch implementation for injecting Mixture of Experts (MoE) capabilities into existing models using LoRA adapters and weight upcycling.

## How to use

...

## License

MIT License - see LICENSE file for details.
